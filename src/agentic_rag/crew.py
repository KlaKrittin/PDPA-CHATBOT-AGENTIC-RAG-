import os
import yaml
from .tools.custom_tool import DocumentSearchTool
from .tools.qdrant_storage import QdrantStorage, MyEmbedder
from langgraph.graph import StateGraph
import logging
from typing import Dict, Any
# Security filter for guardrails
from .tools.security_filter import SecurityFilter
# Import SerperDevTool for web search
try:
    from .tools.serper_tool import SerperDevTool
except ImportError:
    SerperDevTool = None
    logging.warning("SerperDevTool not installed. Please check serper_tool.py if you want web search.")

# Add Ollama Python client
try:
    from ollama import chat as ollama_chat, Client as OllamaClient
except ImportError:
    ollama_chat = None
    OllamaClient = None
    logging.warning("Ollama Python client not installed. Please install with 'pip install ollama'.")

OLLAMA_MODEL = "hf.co/scb10x/typhoon2.1-gemma3-4b-gguf:Q4_K_M"
OLLAMA_HOST = "http://localhost:11434"

AGENTS_YAML = os.path.join(os.path.dirname(__file__), 'config', 'agents.yaml')
TASKS_YAML = os.path.join(os.path.dirname(__file__), 'config', 'tasks.yaml')

# Helper to call Ollama LLM

def call_llm(prompt, system=None):
    if OllamaClient is None:
        raise ImportError("Ollama Python client not installed.")
    messages = []
    if system:
        messages.append({"role": "system", "content": system})
    messages.append({"role": "user", "content": prompt})
    client = OllamaClient(host=OLLAMA_HOST)
    response = client.chat(
        model=OLLAMA_MODEL,
        messages=messages
    )
    return response['message']['content']


def build_langgraph_workflow(pdf_tool=None, use_knowledge_base=True):
    with open(AGENTS_YAML, 'r', encoding='utf-8') as f:
        agents_config = yaml.safe_load(f)
    with open(TASKS_YAML, 'r', encoding='utf-8') as f:
        tasks_config = yaml.safe_load(f)

    # Initialize web search tool if available and API key is set
    web_search_tool = None
    print(f"ðŸ” Checking SerperDevTool availability...")
    print(f"   - SerperDevTool imported: {SerperDevTool is not None}")
    print(f"   - SERPER_API_KEY exists: {os.getenv('SERPER_API_KEY') is not None}")
    
    if SerperDevTool and os.getenv("SERPER_API_KEY"):
        try:
            web_search_tool = SerperDevTool()
            print("âœ… SerperDevTool initialized successfully for LangGraph")
            # Debug: à¸”à¸¹ method à¸—à¸µà¹ˆà¸¡à¸µ
            print(f"ðŸ” SerperDevTool methods: {[m for m in dir(web_search_tool) if not m.startswith('_')]}")
        except Exception as e:
            print(f"âŒ Error initializing SerperDevTool: {e}")
            web_search_tool = None
    else:
        if not SerperDevTool:
            print("âš ï¸ SerperDevTool not available - install serper-dev")
        if not os.getenv("SERPER_API_KEY"):
            print("âš ï¸ SERPER_API_KEY not set - add to .env file")
        print("âš ï¸ Web search will be disabled")

    # Initialize security filter (guardrail)
    security_filter = SecurityFilter()

    # --- Node implementations ---
    def append_progress(state, message):
        progress = state.get("progress_log", [])
        return progress + [message]

    def refine_question_node(state):
        query = state.get("query", "")
        progress_log = state.get("progress_log", [])
        # Guardrail: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸à¹ˆà¸­à¸™ refine à¸«à¸²à¸à¸žà¸šà¸„à¸³à¸«à¸¢à¸²à¸š/à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ à¹ƒà¸«à¹‰à¸«à¸¢à¸¸à¸”à¹à¸¥à¸°à¹à¸ˆà¹‰à¸‡à¹€à¸•à¸·à¸­à¸™
        try:
            filter_result = security_filter.filter_user_input(query or "")
        except Exception:
            filter_result = {"should_respond": False, "response_message": "à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ à¸à¸£à¸¸à¸“à¸²à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆà¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡"}

        if not filter_result.get("should_respond", True):
            progress_log = append_progress({"progress_log": progress_log}, "ðŸ”´ [Guardrail] à¸šà¸¥à¹‡à¸­à¸à¸„à¸³à¸–à¸²à¸¡à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸žà¸šà¸„à¸³à¸«à¸¢à¸²à¸š/à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡")
            warn_msg = filter_result.get("response_message") or "à¸•à¸£à¸§à¸ˆà¸žà¸šà¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¹ƒà¸™à¸„à¸³à¸–à¸²à¸¡ âš ï¸ à¸à¸£à¸¸à¸“à¸²à¸žà¸´à¸¡à¸žà¹Œà¹ƒà¸«à¸¡à¹ˆà¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸–à¹‰à¸­à¸¢à¸„à¸³à¸—à¸µà¹ˆà¸ªà¸¸à¸ à¸²à¸ž"
            return {**state, "response": warn_msg, "best_answer": "", "blocked": True, "progress_log": progress_log}

        # à¸œà¹ˆà¸²à¸™à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¹à¸¥à¹‰à¸§ à¸ˆà¸¶à¸‡à¹€à¸£à¸´à¹ˆà¸¡ refineà¸«
        progress_log = append_progress({"progress_log": progress_log}, "ðŸŸ¡ [LangGraph] à¸à¸³à¸¥à¸±à¸‡à¸›à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡ (Refining question)...")
        system = agents_config['question_refiner_agent']['role'] + "\n" + agents_config['question_refiner_agent']['goal']
        prompt = (
            f"Refine or clarify the following question to make it clear, specific, and actionable.\n"
            f"Question: {query}\n"
            f"à¹‚à¸›à¸£à¸”à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™"
        )
        refined = call_llm(prompt, system=system)
        progress_log = append_progress({"progress_log": progress_log}, "ðŸŸ¢ [LangGraph] à¸›à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ (Refined question)")
        return {**state, "refined_question": refined, "progress_log": progress_log}

    def planning_node(state):
        progress_log = append_progress(state, "ðŸŸ¡ [LangGraph] à¸à¸³à¸¥à¸±à¸‡à¸§à¸²à¸‡à¹à¸œà¸™ (Planning)...")
        refined = state.get("refined_question", "")
        system = agents_config['planning_agent']['role'] + "\n" + agents_config['planning_agent']['goal']
        prompt = (
            f"Generate a step-by-step plan to answer the following question.\n"
            f"Question: {refined}\n"
            f"à¹‚à¸›à¸£à¸”à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™"
        )
        plan = call_llm(prompt, system=system)
        progress_log = append_progress({"progress_log": progress_log}, "ðŸŸ¢ [LangGraph] à¸§à¸²à¸‡à¹à¸œà¸™à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ (Planning done)")
        return {**state, "plan": plan, "progress_log": progress_log}

    def retrieval_node(state):
        progress_log = append_progress(state, "ðŸŸ¡ [LangGraph] à¸à¸³à¸¥à¸±à¸‡à¸„à¹‰à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (Retrieving from PDF/Knowledge)...")
        query = state.get("query", "")  # à¹ƒà¸Šà¹‰ query à¹€à¸”à¸´à¸¡ à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ refined_question
        tool = pdf_tool if pdf_tool else DocumentSearchTool(file_path=os.path.join(os.path.dirname(__file__), '../../knowledge/pdpa.pdf'))
        retrieved = tool._run(query)
        try:
            print("\n===== DocumentSearchTool Result (truncated) =====")
            if isinstance(retrieved, str):
                preview = retrieved[:2000]
                print(preview)
                if len(retrieved) > len(preview):
                    print(f"... [truncated, total {len(retrieved)} chars]")
            else:
                print(str(retrieved))
            print("===== End DocumentSearchTool Result =====\n")
        except Exception as _:
            pass
        progress_log = append_progress({"progress_log": progress_log}, "ðŸŸ¢ [LangGraph] à¸„à¹‰à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ (Retrieval done)")
        return {**state, "retrieved": retrieved, "retrieval_source": "pdf", "progress_log": progress_log}

    def websearch_node(state):
        progress_log = append_progress(state, "ðŸŸ¡ [LangGraph] à¸à¸³à¸¥à¸±à¸‡à¸„à¹‰à¸™à¹€à¸§à¹‡à¸š (Web search fallback)...")
        query = state.get("query", "")  # à¹ƒà¸Šà¹‰ query à¹€à¸”à¸´à¸¡ à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ refined_question
        web_text = ""
        references_text = ""  # à¹€à¸žà¸´à¹ˆà¸¡à¸šà¸£à¸£à¸—à¸±à¸”à¸™à¸µà¹‰à¹€à¸žà¸·à¹ˆà¸­à¸›à¹‰à¸­à¸‡à¸à¸±à¸™ error
        
        if web_search_tool:
            try:
                print(f"ðŸ” Trying to call SerperDevTool with query: '{query}'")
                print(f"ðŸ” Available methods: {[m for m in dir(web_search_tool) if not m.startswith('_')]}")
                
                # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š schema à¸‚à¸­à¸‡ tool
                if hasattr(web_search_tool, 'args_schema'):
                    print(f"ðŸ” Tool args_schema: {web_search_tool.args_schema}")
                    if hasattr(web_search_tool.args_schema, '__annotations__'):
                        print(f"ðŸ” Tool annotations: {web_search_tool.args_schema.__annotations__}")
                if hasattr(web_search_tool, 'schema'):
                    print(f"ðŸ” Tool schema: {web_search_tool.schema}")
                
                # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š signature à¸‚à¸­à¸‡ run method
                import inspect
                if hasattr(web_search_tool, 'run'):
                    try:
                        sig = inspect.signature(web_search_tool.run)
                        print(f"ðŸ” run method signature: {sig}")
                    except Exception as e:
                        print(f"ðŸ” Cannot inspect run method: {e}")
                
                # à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ method à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
                web_result = None
                
                # à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ run method à¹à¸šà¸š keyword argument à¸à¹ˆà¸­à¸™
                if hasattr(web_search_tool, 'run'):
                    print("ðŸ” Trying run method with keyword argument")
                    try:
                        web_result = web_search_tool.run(query=query)
                        print("âœ… run method with keyword argument succeeded")
                    except Exception as e:
                        print(f"ðŸ” run method with keyword failed: {e}")
                        try:
                            # à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ run method à¹à¸šà¸š positional argument
                            web_result = web_search_tool.run(query)
                            print("âœ… run method with positional argument succeeded")
                        except Exception as e2:
                            print(f"ðŸ” run method with positional failed: {e2}")
                
                # à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ à¸¥à¸­à¸‡à¹ƒà¸Šà¹‰ _run method
                if web_result is None and hasattr(web_search_tool, '_run'):
                    print("ðŸ” Trying _run method")
                    try:
                        web_result = web_search_tool._run(query)
                        print("âœ… _run method succeeded")
                    except Exception as e:
                        print(f"ðŸ” _run method failed: {e}")
                
                # à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰ à¸¥à¸­à¸‡à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¹‚à¸”à¸¢à¸•à¸£à¸‡
                if web_result is None:
                    print("ðŸ” Trying direct call")
                    try:
                        web_result = web_search_tool.search(query)
                        print("âœ… .search method succeeded")
                    except Exception as e:
                        print(f"ðŸ” .search method failed: {e}")
                
                # à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹€à¸¥à¸¢
                if web_result is None:
                    raise Exception("à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰ SerperDevTool à¹„à¸”à¹‰")
                
                if isinstance(web_result, dict) and 'organic' in web_result:
                    # à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹à¸¥à¸°à¸¥à¸´à¸‡à¸à¹Œà¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡
                    results = web_result['organic']
                    web_text_parts = []
                    references = []
                    web_contents = []
                    for i, result in enumerate(results):  # à¸”à¸¶à¸‡à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸—à¸¸à¸à¸¥à¸´à¸‡à¸à¹Œ
                        title = result.get('title', '')
                        snippet = result.get('snippet', '')
                        link = result.get('link', '')
                        print(f"ðŸŒ [{i+1}] à¸­à¹ˆà¸²à¸™à¸¥à¸´à¸‡à¸à¹Œ: {link}")
                        web_text_parts.append(f"{i+1}. {title}\n{snippet}")
                        references.append(f"[{i+1}] {title}: {link}")
                        # à¸”à¸¶à¸‡à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸ˆà¸²à¸à¹€à¸§à¹‡à¸š
                        from src.agentic_rag.tools.serper_tool import SerperDevTool
                        content = SerperDevTool.extract_web_content(link, max_chars=1000000)
                        print(f"    â†³ à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¹„à¸”à¹‰: {len(content)} à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£")
                        print(f"    â†³ à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸—à¸µà¹ˆà¸”à¸¶à¸‡à¹„à¸”à¹‰à¸ˆà¸²à¸à¸¥à¸´à¸‡à¸à¹Œà¸™à¸µà¹‰:\n{content}")
                        web_contents.append(f"---\n{title}\n{link}\n{content}\n")
                    web_text = '\n\n'.join(web_text_parts) + '\n\n' + '\n'.join(web_contents)
                    references_text = '\n'.join(references)
                    print(f"âœ… [LangGraph] Web search successful, found {len(results)} results")
                    print(f"ðŸ“š References: {len(references)} sources")
                    print(f"ðŸ“ à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸£à¸§à¸¡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸•à¸­à¸š (web_text):\n{web_text}")
                else:
                    web_text = str(web_result)
                    references_text = ""
                    print(f"âœ… [LangGraph] Web search successful, raw result")
            except Exception as e:
                print(f"âŒ [LangGraph] Web search error: {e}")
                web_text = "à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¹‰à¸™à¹€à¸§à¹‡à¸šà¹„à¸”à¹‰"
        else:
            web_text = "à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¹‰à¸™à¹€à¸§à¹‡à¸šà¹„à¸”à¹‰ (SerperDevTool à¹„à¸¡à¹ˆà¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¸¡à¸µ API Key)"
            print("âš ï¸ [LangGraph] Web search not available")
        
        # Combine with previous retrieved
        combined = f"[PDF/Knowledge]: {state.get('retrieved', '')}\n[Web]: {web_text}"
        progress_log = append_progress({"progress_log": progress_log}, "ðŸŸ¢ [LangGraph] à¸„à¹‰à¸™à¹€à¸§à¹‡à¸šà¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ (Web search done)")
        return {**state, "retrieved": combined, "retrieval_source": "pdf+web", "web_search_count": state.get("web_search_count", 0) + 1, "web_references": references_text, "progress_log": progress_log}

    def judge_info_node(state):
        progress_log = append_progress(state, "ðŸŸ¡ [LangGraph] LLM à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸„à¸§à¸²à¸¡à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (Judging info sufficiency)...")
        refined = state.get("refined_question", "")
        context = state.get("retrieved", "")
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸ˆà¸³à¸™à¸§à¸™à¸„à¸£à¸±à¹‰à¸‡à¸—à¸µà¹ˆà¸žà¸¢à¸²à¸¢à¸²à¸¡à¸„à¹‰à¸™à¸«à¸²à¹à¸¥à¹‰à¸§
        web_search_count = state.get("web_search_count", 0)
        if web_search_count >= 3:
            print("ðŸŸ¡ [LangGraph] à¹€à¸à¸´à¸™à¸ˆà¸³à¸™à¸§à¸™à¸„à¸£à¸±à¹‰à¸‡à¸—à¸µà¹ˆà¸žà¸¢à¸²à¸¢à¸²à¸¡à¸„à¹‰à¸™à¸«à¸²à¹à¸¥à¹‰à¸§ - à¸ˆà¸°à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ")
            return {**state, "info_sufficient": True, "judge_reason": "à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µà¸«à¸¥à¸±à¸‡à¸ˆà¸²à¸à¸žà¸¢à¸²à¸¢à¸²à¸¡à¸„à¹‰à¸™à¸«à¸²à¹à¸¥à¹‰à¸§", "progress_log": progress_log}
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¡à¸µà¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
        if not context or context.strip() in ["à¹„à¸¡à¹ˆà¸žà¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡", "à¹‚à¸›à¸£à¸”à¸•à¸±à¹‰à¸‡à¸„à¸³à¸–à¸²à¸¡à¹€à¸‰à¸žà¸²à¸°à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š PDPA à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™", "à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¹‰à¸™à¹€à¸§à¹‡à¸šà¹„à¸”à¹‰"]:
            print("ðŸŸ¡ [LangGraph] à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­ - à¸ˆà¸°à¹ƒà¸Šà¹‰ web search")
            return {**state, "info_sufficient": False, "judge_reason": "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­", "web_search_count": web_search_count + 1, "progress_log": progress_log}
        
        system = "à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸—à¸µà¹ˆà¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¹ƒà¸™à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸„à¸§à¸²à¸¡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡"
        prompt = (
            f"à¸„à¸³à¸–à¸²à¸¡: {refined}\n"
            f"à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸„à¹‰à¸™à¸žà¸š: {context}\n"
            f"à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸µà¹‰à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ?\n"
            f"à¸–à¹‰à¸²à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­ à¸•à¸­à¸šà¸§à¹ˆà¸² 'à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­'\nà¸–à¹‰à¸²à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­ à¸•à¸­à¸šà¸§à¹ˆà¸² 'à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­' à¹à¸¥à¸°à¸£à¸°à¸šà¸¸à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¸²à¸”à¸­à¸°à¹„à¸£\nà¹‚à¸›à¸£à¸”à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™"
        )
        judge = call_llm(prompt, system=system)
        progress_log = append_progress({"progress_log": progress_log}, f"ðŸŸ¢ [LangGraph] LLM à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¹à¸¥à¹‰à¸§: {judge.strip()}")
        # Simple logic: if 'à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­' in answer and not 'à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­' => sufficient
        is_sufficient = ('à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­' in judge and 'à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­' not in judge)
        return {**state, "info_sufficient": is_sufficient, "judge_reason": judge.strip(), "progress_log": progress_log}

    def generate_answers_node(state):
        progress_log = append_progress(state, "ðŸŸ¡ [LangGraph] à¸à¸³à¸¥à¸±à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸•à¸­à¸š (Generating answer)...")
        refined = state.get("refined_question", "")
        context = state.get("retrieved", "")
        system = agents_config['answer_candidate_agent']['role'] + "\n" + agents_config['answer_candidate_agent']['goal']
        prompt = (
            f"Using the following context, write ONE comprehensive, structured answer to the question.\n"
            f"Context: {context}\n"
            f"Question: {refined}\n"
            f"\nà¸‚à¹‰à¸­à¸à¸³à¸«à¸™à¸”:\n"
            f"- à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸Šà¸´à¸‡à¸à¸Žà¸«à¸¡à¸²à¸¢à¸ à¸²à¸¢à¹ƒà¸•à¹‰ PDPA à¸‚à¸­à¸‡à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\n"
            f"- à¸«à¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­ à¸£à¸°à¸šà¸¸à¸§à¹ˆà¸² 'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­' à¹à¸¥à¸°à¹à¸™à¸°à¸™à¸³à¸—à¸²à¸‡à¸›à¸à¸´à¸šà¸±à¸•à¸´\n"
            f"- à¸•à¸­à¸šà¸„à¸£à¸šà¸—à¸¸à¸à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸‚à¸­à¸‡à¸„à¸³à¸–à¸²à¸¡à¹à¸¥à¸°à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸¡à¸²à¸•à¸£à¸²à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸±à¸”à¹€à¸ˆà¸™\n"
            f"- à¸ˆà¸±à¸”à¸£à¸¹à¸›à¹à¸šà¸šà¹€à¸›à¹‡à¸™à¸«à¸±à¸§à¸‚à¹‰à¸­à¸¢à¹ˆà¸­à¸¢ à¸à¸£à¸°à¸Šà¸±à¸š à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ (à¸ à¸²à¸©à¸²à¹„à¸—à¸¢)\n"
        )
        answer = call_llm(prompt, system=system).strip()
        progress_log = append_progress({"progress_log": progress_log}, "ðŸŸ¢ [LangGraph] à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸•à¸­à¸šà¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ (Single answer generated)")
        return {**state, "best_answer": answer, "progress_log": progress_log}

    # Ranking step removed entirely; generation already yields single best answer

    def response_node(state):
        progress_log = append_progress(state, "ðŸŸ¡ [LangGraph] à¸à¸³à¸¥à¸±à¸‡à¸ªà¸£à¸¸à¸›à¸„à¸³à¸•à¸­à¸š (Synthesizing response)...")
        ranked = state.get("ranked", [])
        best_answer = state.get("best_answer", "")
        web_references = state.get("web_references", "")
        
        if best_answer:
            # à¸ˆà¸±à¸”à¸£à¸¹à¸›à¹à¸šà¸šà¸„à¸³à¸•à¸­à¸šà¹ƒà¸«à¹‰à¸à¸£à¸°à¸Šà¸±à¸š à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¹à¸¥à¸°à¸„à¸£à¸šà¸›à¸£à¸°à¹€à¸”à¹‡à¸™
            system = agents_config['response_synthesizer_agent']['role'] + "\n" + agents_config['response_synthesizer_agent']['goal']
            prompt = (
                f"à¸ˆà¸±à¸”à¸£à¸¹à¸›à¹à¸šà¸šà¸„à¸³à¸•à¸­à¸šà¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰à¹ƒà¸«à¹‰à¸à¸£à¸°à¸Šà¸±à¸š à¹€à¸›à¹‡à¸™à¸«à¸±à¸§à¸‚à¹‰à¸­à¸¢à¹ˆà¸­à¸¢à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¸—à¸¸à¸à¸„à¸³à¸–à¸²à¸¡à¸¢à¹ˆà¸­à¸¢ à¹à¸¥à¸°à¹„à¸¡à¹ˆà¹€à¸žà¸´à¹ˆà¸¡à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¹ƒà¸«à¸¡à¹ˆ:\n"
                f"à¸„à¸³à¸•à¸­à¸šà¹€à¸”à¸´à¸¡: {best_answer}\n"
                f"\nâš ï¸ à¸à¸Žà¸ªà¸³à¸„à¸±à¸:\n"
                f"- à¸•à¹‰à¸­à¸‡à¸•à¸­à¸šà¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸•à¸²à¸¡ à¸ž.à¸£.à¸š. à¸„à¸¸à¹‰à¸¡à¸„à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¹ˆà¸§à¸™à¸šà¸¸à¸„à¸„à¸¥ à¸ž.à¸¨. 2562 à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\n"
                f"- à¸«à¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­ à¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸à¸§à¹ˆà¸² 'à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­' à¹à¸¥à¸°à¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸›à¸£à¸¶à¸à¸©à¸²à¸œà¸¹à¹‰à¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸\n"
                f"- à¹ƒà¸Šà¹‰ bullet points (â€¢) à¹à¸¥à¸°à¸«à¸±à¸§à¸‚à¹‰à¸­à¸¢à¹ˆà¸­à¸¢à¹ƒà¸«à¹‰à¸Šà¸±à¸”à¹€à¸ˆà¸™\n"
                f"- à¹€à¸™à¹‰à¸™à¸„à¸§à¸²à¸¡à¸à¸£à¸°à¸Šà¸±à¸š à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¹à¸¥à¸°à¸„à¸£à¸šà¸›à¸£à¸°à¹€à¸”à¹‡à¸™\n"
                f"- à¹„à¸¡à¹ˆà¹€à¸žà¸´à¹ˆà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸¡à¹ˆà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸™à¸„à¸³à¸•à¸­à¸šà¹€à¸”à¸´à¸¡\n"
                f"\nà¹‚à¸›à¸£à¸”à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™"
            )
            response = call_llm(prompt, system=system)
        else:
            # Fallback to synthesizing from ranked answers
            system = agents_config['response_synthesizer_agent']['role'] + "\n" + agents_config['response_synthesizer_agent']['goal']
            prompt = (
                f"Select the top-ranked answer and format it as the final response.\n"
                f"Answers: {ranked}\n"
                f"\nâš ï¸ à¸à¸Žà¸ªà¸³à¸„à¸±à¸: à¸•à¹‰à¸­à¸‡à¸•à¸­à¸šà¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸•à¸²à¸¡ à¸ž.à¸£.à¸š. à¸„à¸¸à¹‰à¸¡à¸„à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¹ˆà¸§à¸™à¸šà¸¸à¸„à¸„à¸¥ à¸ž.à¸¨. 2562 à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\n"
                f"à¹‚à¸›à¸£à¸”à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™"
            )
            response = call_llm(prompt, system=system)
        
        progress_log = append_progress({"progress_log": progress_log}, "ðŸŸ¢ [LangGraph] à¸ªà¸£à¸¸à¸›à¸„à¸³à¸•à¸­à¸šà¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§ (Response ready)")
        return {**state, "response": response, "best_answer": best_answer, "web_references": web_references, "progress_log": progress_log}

    # --- Build the graph ---
    graph = StateGraph(Dict[str, Any])
    graph.add_node("refine_question", refine_question_node)
    graph.add_node("planning", planning_node)
    graph.add_node("retrieval", retrieval_node)
    graph.add_node("websearch", websearch_node)
    graph.add_node("judge_info", judge_info_node)
    graph.add_node("generate_answers", generate_answers_node)
    # select_best node removed
    graph.add_node("response", response_node)

    # Wiring: retrieval -> judge_info
    graph.set_entry_point("refine_question")
    graph.add_conditional_edges(
        "refine_question",
        lambda state: "response" if state.get("blocked") else "planning"
    )
    graph.add_edge("planning", "retrieval")
    graph.add_edge("retrieval", "judge_info")
    # If info sufficient, go to generate_answers; else, go to websearch
    graph.add_conditional_edges(
        "judge_info",
        lambda state: "generate_answers" if state.get("info_sufficient") else "websearch"
    )
    # After websearch, judge again
    graph.add_edge("websearch", "judge_info")
    # After info is sufficient, continue as before
    graph.add_edge("generate_answers", "response")
    graph.set_finish_point("response")

    return graph.compile()
